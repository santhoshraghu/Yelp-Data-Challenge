{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsized_data = pd.read_csv(r\"C:\\Users\\Atharva Kulkarni\\Desktop\\WPI_Courses\\Semester-2\\NLP\\Final_project\\pre_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(downsized_data['text'], downsized_data['stars'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import RobertaModel, RobertaTokenizer, RobertaForSequenceClassification\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "from torch import nn,optim\n",
    "from torch.utils.data import Dataset,DataLoader,TensorDataset, RandomSampler, SequentialSampler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_model = 'roberta-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=RobertaTokenizer.from_pretrained(pre_trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_token_lens = []\n",
    "for txt in x_train:\n",
    "  tokens = tokenizer.encode(txt, max_length=512, truncation=True)\n",
    "  x_train_token_lens.append(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_token_lens = []\n",
    "for txt in x_test:\n",
    "  tokens = tokenizer.encode(txt, max_length=512, truncation=True)\n",
    "  x_test_token_lens.append(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LENGTH = 240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.tolist()\n",
    "x_test = x_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_ids = [tokenizer.encode(x_train[i],add_special_tokens = True, max_length=MAX_SEQ_LENGTH, truncation=True) for i in range(0,len(x_train))]\n",
    "test_input_ids = [tokenizer.encode(x_test[i],add_special_tokens = True, max_length=MAX_SEQ_LENGTH, truncation=True) for i in range(0,len(x_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "train_input_ids = pad_sequences(train_input_ids, maxlen=MAX_SEQ_LENGTH, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n",
    "test_input_ids = pad_sequences(test_input_ids, maxlen=MAX_SEQ_LENGTH, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_attention_masks = [[int(token_id > 0) for token_id in review]for review in train_input_ids]\n",
    "test_attention_masks = [[int(token_id > 0) for token_id in review] for review in test_input_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = torch.tensor(train_input_ids)\n",
    "test_inputs = torch.tensor(test_input_ids)\n",
    "train_labels = torch.tensor(y_train.values)\n",
    "test_labels = torch.tensor(y_test.values)\n",
    "train_masks = torch.tensor(train_attention_masks)\n",
    "test_masks = torch.tensor(test_attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = y_train.nunique()\n",
    "n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained(\n",
    "    \"roberta-base\",\n",
    "    num_labels = 2,\n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=2\n",
    "optimizer=AdamW(model.parameters(),lr=3e-5)\n",
    "total_steps=len(train_dataloader)*epochs\n",
    "scheduler=get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "loss_fn=nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    # Round to the nearest second\n",
    "    elapsed_round = int(round(elapsed))\n",
    "    # Format time in hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds = elapsed_round))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, labels):\n",
    "    preds = np.argmax(preds, axis=1).flatten()\n",
    "    labels = labels.flatten()\n",
    "    return np.sum(preds == labels) / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train_values = []\n",
    "acc_train_values = []\n",
    "loss_val_values = []\n",
    "acc_val_values = []\n",
    "for epoch in range(0,epochs):\n",
    "\n",
    "        #             --- Train---\n",
    "\n",
    "        # Perform forward pass over the training dataset\n",
    "        print(\"\\n Epoch {:}/{:} :\".format(epoch+1,epochs))\n",
    "        print('Training....')\n",
    "\n",
    "        # Measure how long the training epoch takes\n",
    "        t0 = time.time()\n",
    "        # Reset total loss and accuracy for this epoch\n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "\n",
    "        # Put the model in training mode\n",
    "        model.train()\n",
    "\n",
    "        # For each batch of training data\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            # Update progress for each 100 steps\n",
    "            if (step % 100==0) & (not step==0):\n",
    "                # Calculate elapsed time in minutes\n",
    "                elapsed = format_time((time.time()-t0))\n",
    "                # Report progress\n",
    "                print(' Batch {:>5,} of {:>5,}. Elapsed:{:}.'.format(step,len(train_dataloader),elapsed))\n",
    "\n",
    "            # Unpack training batch from trainloader and move to GPU\n",
    "            b_input_ids = batch[0].long().to(device)  # 0 - input ids tensor\n",
    "            b_attention_mask = batch[1].long().to(device) # 1 - input masks tensor\n",
    "            b_labels = batch[2].long().to(device) # 2 - labels tensor\n",
    "\n",
    "            # Clear any previously calculated gradients in Pytorch before performing a backward pass\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Output the results\n",
    "            outputs = model(input_ids = b_input_ids, attention_mask = b_attention_mask, labels=b_labels) # Return tuple\n",
    "            # Loss value from output\n",
    "            loss = outputs.loss   # Loss\n",
    "\n",
    "            # Update total loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = outputs.logits  # Output probabilities\n",
    "            # Move logits and labels to CPU\n",
    "            preds = preds.detach().cpu().numpy()\n",
    "            label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "            # Calculate the accuracy for this batch\n",
    "            tmp_train_accuracy = accuracy(preds, label_ids)\n",
    "\n",
    "            # Accumulate the total accuracy\n",
    "            total_acc += tmp_train_accuracy\n",
    "\n",
    "            # Perform a backward pass to calculate gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # To avoid exploding vanishing gradients problem, clip the norm of the gradients to 1.0\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(),1.0)\n",
    "\n",
    "            # Update the parameters (weights)\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update the learning rate\n",
    "            scheduler.step()\n",
    "\n",
    "        # Calculate the average loss over training data\n",
    "        avg_total_loss = total_loss/len(train_dataloader)\n",
    "\n",
    "        # Store the loss values\n",
    "        loss_train_values.append(avg_total_loss)\n",
    "\n",
    "        # Calculate the average accuracy over the training data\n",
    "        avg_train_acc = total_acc / len(train_dataloader)\n",
    "\n",
    "        # Store the accuracy values\n",
    "        acc_train_values.append(avg_train_acc)\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"\\nAverage training accuracy: {0:.2f}\".format(avg_train_acc))\n",
    "\n",
    "        print('Average training loss : {0:.2f}'.format(avg_total_loss))\n",
    "        print('Training epoch took: {:}'.format(format_time(time.time()- t0)))\n",
    "\n",
    "        #             --- VALIDATION ---\n",
    "\n",
    "\n",
    "        # After each epoch perform validation to check model performance\n",
    "        print('\\n Running validation...')\n",
    "\n",
    "        t0 = time.time()\n",
    "        # Put model in evaluation mode\n",
    "        model.eval()\n",
    "\n",
    "        # Tracking variables\n",
    "        total_eval_accuracy = 0\n",
    "        total_eval_loss = 0\n",
    "\n",
    "        # Unpack validation batch from trainloader and move to GPU\n",
    "        for batch in test_dataloader:\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "\n",
    "            # Tell model not to compute gradients to save memory and accelerate validation\n",
    "            with torch.no_grad():\n",
    "                # Forward pass, calculate logit prediction\n",
    "                 outputs = model(b_input_ids,\n",
    "                                   token_type_ids=None,\n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "            # Update total evaluation loss\n",
    "            total_eval_loss += loss.item()\n",
    "\n",
    "            # Move logits and labels to CPU\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "            # Calculate the accuracy for this batch and accumulate it over all batches\n",
    "            total_eval_accuracy += accuracy(logits, label_ids)\n",
    "\n",
    "        # Compute the average accuracy over all of the batches\n",
    "        avg_val_accuracy = total_eval_accuracy / len(test_dataloader)\n",
    "\n",
    "        # Store the accuracy values\n",
    "        acc_val_values.append(avg_val_accuracy)\n",
    "\n",
    "        # Compute the average loss over all of the batches\n",
    "        avg_val_loss = total_eval_loss / len(test_dataloader)\n",
    "\n",
    "         # Store the loss values\n",
    "        loss_val_values.append(avg_val_loss)\n",
    "\n",
    "    # Measure how long the validation run took.\n",
    "        validation_time = format_time(time.time() - t0)\n",
    "        print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "        print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "        print(\"  Validation took: {:}\".format(validation_time))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
